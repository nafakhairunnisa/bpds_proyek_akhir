# -*- coding: utf-8 -*-
"""Salinan dari notebook-akhir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18M0UB61QWFR7ww6pfyjRnC8Cs78U0vbq

# Proyek Akhir: Menyelesaikan Permasalahan Institusi Pendidikan

- Nama: Nafa Khairunnisa
- Email: nkhairunn2412@gmail.com
- Id Dicoding: nafa-khairunnisa

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

# Libraries yang sering digunakan
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math
import os
import json
import joblib

# Libraries untuk data preparation
from scipy.stats.mstats import winsorize
from sklearn.model_selection import train_test_split
from scipy.stats import chi2_contingency, ttest_ind
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTENC
from sklearn.preprocessing import OrdinalEncoder

# Libraries untuk modeling
import pickle
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Feature Engineering Tambahan
from sklearn.preprocessing import PolynomialFeatures
from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import GridSearchCV

"""### Menyiapkan data yang akan digunakan"""

# Data Loading
url = "https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv"
df = pd.read_csv(url, sep=';')

df.head()

"""## Data Understanding

Pada tahapan ini, dataset student performance dibaca dan dipahami untuk mengetahui informasi yang ada dalam dataset dan mencari hubungan antar fitur yang menyebabkan mahasiswa drop out.
"""

# Info dataset
df.info()

"""**Insights**:

- Dataset memiliki total 4424 sampel.
- Terdiri 7 fitur bertipe data float, 29 fitur bertipe data integer, dan 1 fitur bertipe data object.
- Fitur status merupakan label target klasifikasi.
"""

# Deskripsi variabel
df.describe().T

"""**Insights**: </br>
Terdapat gap yang sangat besar pada fitur course yaitu nilai minimum 33 dan maksimum 9991.
"""

# Cek jumlah data duplikat
df_duplicated = df.duplicated().sum()
print("Jumlah data duplikat : ", df_duplicated)

# Cek missing value
df.isna().sum()

"""**Insights**: </br>
- Tidak ada data duplikat maupun missing value.
"""

# Cek nilai unique
df.nunique()

# Cek nilai unique

# Marital_status
print("Marital_status :", df['Marital_status'].unique())

# Application_mode
print("Application_mode :", df['Application_mode'].unique())

# Course
print("Course :", df['Course'].unique())

# Previous_qualification
print("Previous_qualification :", df['Previous_qualification'].unique())

# Nacionality
print("Nacionality :", df['Nacionality'].unique())

# Mothers_qualification
print("Mothers_qualification :", df['Mothers_qualification'].unique())

# Fathers_qualification
print("Fathers_qualification :", df['Fathers_qualification'].unique())

# Mothers_occupation
print("Mothers_occupation :", df['Mothers_occupation'].unique())

# Fathers_occupation
print("Fathers_occupation :", df['Fathers_occupation'].unique())

# Status
print("Status :", df['Status'].unique())

# Cek nilai Course
print("Nilai terkecil:", df['Course'].min())
print("Nilai terbesar:", df['Course'].max())
print("10 nilai Course teratas:")
print(df['Course'].value_counts().head(10))

print("10 nilai Course terbawah:")
print(df['Course'].value_counts().tail(10))

"""### EDA

Exploratory Data Analysis dilakukan untuk mengeksplor data dan mencari pengetahuan dari data. Pada kasus ini, tujuannya untuk mengetahui fitur apa saja yang berpengaruh pada distribusi status mahasiswa.
"""

print(df.columns)

"""#### Univariate analysis"""

# Cek distribusi kategorikal data
categorical_cols = ['Course', 'Application_mode', 'Marital_status', 'Daytime_evening_attendance',
                    'Previous_qualification', 'Nacionality', 'Mothers_qualification', 'Fathers_qualification',
                    'Mothers_occupation', 'Fathers_occupation', 'Displaced', 'Educational_special_needs', 'Debtor',
                    'Tuition_fees_up_to_date', 'Gender', 'Scholarship_holder', 'International']
for col in categorical_cols:
    df[col] = df[col].astype('category')

"""Beberapa fitur yang seharusnya categorical dikonversi menjadi string untuk keperluan visualisasi data dan mencari korelasi."""

# Plot distribusi kategori
num_plots = len(categorical_cols)

fig, axes = plt.subplots(nrows=num_plots, figsize=(12, 4 * num_plots))

for i, col in enumerate(categorical_cols):
    value_counts = df[col].value_counts()

    sns.barplot(
        x=value_counts.index,
        y=value_counts.values,
        color='skyblue',
        ax=axes[i]
    )
    axes[i].set_title(f'Distribusi Kategori: {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Jumlah')

plt.tight_layout()
plt.show()

"""**Insights**: </br>
- Populasi mayoritas adalah mahasiswa lokal, laki-laki, belum menikah, belajar di malam hari.
- Kebanyakan mahasiswa berasal dari latar belakang keluarga dengan pendidikan dan pekerjaan rendah.
- Sebagian besar membayar tepat waktu dan memiliki utang.
- Penerima beasiswa dan mahasiswa dengan kebutuhan khusus cukup sedikit.
- Fitur-fitur seperti Previous_qualification, Application_mode, dan Attendance_time memiliki kemungkinan menjadi fitur penting untuk prediksi kelulusan mahasiswa.
"""

# Cek distribusi numerikal data
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

n_cols = 2
n_rows = (len(numerical_cols) + n_cols - 1) // n_cols

# Plot
plt.figure(figsize=(n_cols*6, n_rows*4))

for idx, col in enumerate(numerical_cols):
    plt.subplot(n_rows, n_cols, idx + 1)
    sns.histplot(df[col], kde=True, bins=28, color='skyblue')
    plt.title(f'Distribusi: {col}')
    plt.xlabel(col)
    plt.ylabel('Frekuensi')

plt.tight_layout()
plt.show()

"""**Insights**: </br>
- Banyak fitur menunjukkan distribusi right-skewed, artinya mayoritas data berada di nilai rendah, tetapi ada outlier bernilai tinggi.
- Fitur grade relatif simetris dan mendekati distribusi normal.
- Ada indikasi tidak aktifnya mahasiswa dalam bentuk nilai 0 yang sering muncul (terutama pada fitur credited, evaluations, dan without_evaluations).
- Beberapa distribusi menunjukkan kesenjangan besar dalam performa atau partisipasi mahasiswa.
"""

# Cek outliers dengan boxplot
n = len(numerical_cols)
cols = 5
rows = math.ceil(n / cols)

plt.figure(figsize=(20, rows * 3))
for i, feature in enumerate(numerical_cols, 1):
    plt.subplot(rows, cols, i)
    sns.boxplot(x=df[feature])
    plt.title(f'Boxplot: {feature}')

plt.tight_layout()
plt.show()

# Cek jumlah outliers
Q1 = df[numerical_cols].quantile(0.25)
Q3 = df[numerical_cols].quantile(0.75)
IQR = Q3 - Q1

outlier_mask = (df[numerical_cols] < (Q1 - 1.5 * IQR)) | (df[numerical_cols] > (Q3 + 1.5 * IQR))

outliers_per_feature = outlier_mask.sum()

print("Jumlah outlier per fitur:")
print(outliers_per_feature.sort_values(ascending=False))

total_outliers = outlier_mask.sum().sum()
print(f"\nTotal jumlah outlier (sel): {total_outliers}")

# Cek distribusi Status

# Hitung jumlah masing-masing kategori Status
status_counts = df['Status'].value_counts()
labels = ['Dropout (0)', 'Graduate (1),', 'Enrolled (2)']
colors = ["#72BCD4", "#D3D3D3", "#8ad8ed"]

# Pie chart
plt.figure(figsize=(6,6))
plt.pie(status_counts, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors)
plt.title('Distribusi Status Rate')
plt.axis('equal')
plt.show()

"""Insight: </br>
Dari hasil visualisasi di atas, persentase mahasiswa yang dropout merupakan yang terbanyak dan hampir setengahnya dari keseluruhan. Hal ini menandakan bahwa ada faktor yang menyebabkan mahasiswa gugur sebelum lulus.

#### Multivariate analysis
"""

df.info()

# Korelasi fitur kategorikal dengan label target 'Status'

# Menghitung jumlah kemunculan tiap kategori dalam fitur kategorikal terhadap setiap Status
for col in ["Course", "Daytime_evening_attendance", "Application_mode", "Application_order", "Marital_status", "Nacionality"]:
    print(f"\nDistribusi fitur '{col}' berdasarkan Status:")
    print(df.groupby("Status")[col].value_counts().unstack().fillna(0))

# Distribusi Status Mahasiswa berdasarkan Kehadiran dan Status Pernikahan

# Palet warna pastel untuk Status
status_palette = {
    "Dropout": "#f94144",
    "Enrolled": "#f9c74f",
    "Graduate": "#90be6d"
}

# Fungsi visualisasi countplot
def plot_countplot_by_feature(df, feature_name, title=None, xlabel=None):
    sns.set(style="whitegrid")
    plt.figure(figsize=(10, 5))

    sns.countplot(data=df, x=feature_name, hue="Status", palette=status_palette)

    plt.title(title or f"Distribusi Status Mahasiswa berdasarkan {feature_name}")
    plt.xlabel(xlabel or feature_name)
    plt.ylabel("Jumlah Mahasiswa")
    plt.legend(title="Status")
    plt.tight_layout()
    plt.show()

# Pemanggilan fungsi
plot_countplot_by_feature(df, "Daytime_evening_attendance",
                          "Distribusi Status Mahasiswa berdasarkan Kehadiran",
                          "Attendance (0 = Daytime, 1 = Evening)")

plot_countplot_by_feature(df, "Marital_status",
                          "Distribusi Status Mahasiswa berdasarkan Status Pernikahan",
                          "Status Pernikahan (1 – single 2 – married 3 – widower 4 – divorced 5 – facto union 6 – legally separated)")

"""Insights: </br>
- Mayoritas mahasiswa mengikuti kelas malam (evening). Dari kelompok ini, jumlah mahasiswa yang lulus (graduate) paling tinggi, diikuti oleh dropout, dan yang masih aktif (enrolled).
- Sementara pada kelas siang (daytime), jumlah mahasiswa yang dropout sedikit lebih tinggi dibanding graduate, menunjukkan bahwa jadwal kuliah siang hari bisa menjadi tantangan bagi sebagian mahasiswa.
- Sebagian besar mahasiswa berstatus belum menikah (single). Dari kelompok ini, mayoritas berhasil menyelesaikan studi (graduate), diikuti oleh dropout.
- Pada mahasiswa yang sudah menikah (married), jumlah dropout lebih tinggi dibanding graduate, yang bisa mengindikasikan bahwa tanggung jawab rumah tangga dapat memengaruhi keberhasilan studi.
- Status pernikahan lain seperti divorced, widower, dan legally separated sangat sedikit jumlahnya, sehingga tidak bisa dijadikan acuan umum.
"""

# Distirbusi Status berdasarkan Coursem Application mode, application order, dan nacionality

# Fungsi visualisasi
def plot_stacked_bar_by_feature(df, feature_name, title=None, xlabel=None):
    ct = pd.crosstab(df[feature_name], df['Status'])
    pastel_colors = [status_palette[status] for status in ct.columns]

    ct.plot(kind='bar', stacked=True, figsize=(12, 6), color=pastel_colors)

    plt.title(title or f"Distribusi Status Mahasiswa per {feature_name}")
    plt.ylabel("Jumlah Mahasiswa")
    plt.xlabel(xlabel or feature_name)
    plt.xticks(rotation=45, ha='right')
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.legend(title="Status")
    plt.tight_layout()
    plt.show()

#Vsualisasi masing-masing fitur
plot_stacked_bar_by_feature(df, 'Course', "Distribusi Status Mahasiswa per Course", "Kode Course")
plot_stacked_bar_by_feature(df, 'Application_mode', "Distribusi Status Mahasiswa per Application Mode", "Kode Application Mode")
plot_stacked_bar_by_feature(df, 'Application_order', "Distribusi Status Mahasiswa per Application Order", "Application Order (0 - first choice; and 9 last choice))")
plot_stacked_bar_by_feature(df, 'Nacionality', "Distribusi Status Mahasiswa per Nacionality", "Kode Nacionality")

"""**Insights**: </br>
- Mahasiswa dari kode course 9500 paling banyak lulus. Sedangkan pada course lainlebih sedikit tidak sampai 400 jumlahnya. Ini menandakan bahwa course lain kurang diminati atau sulit untuk lulus. Untuk dropout tertinggi ada pada course dengan kode 9147 dan 9991.
- Mahasiswa paling banyak lulus melalui application mode 1. Sedangkan yang dropout pada application mode 39.
- Distribusi terbanyak ada pada application order second choice baik pada graduated, dropout, dan enrolled.
- Semua mahasiswa mempunyai nacionality kode 1.
"""

# Korelasi antar kolom numerik
plt.figure(figsize=(20, 12))
sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Korelasi antar fitur numerik')
plt.show()

"""Insights:
- Fitur-fitur akademik seperti Curricular_units_credited, enrolled, approved, dan grade menunjukkan korelasi yang sangat kuat satu sama lain, baik pada semester pertama maupun kedua (korelasi ≥ 0.75). Hal ini mencerminkan bahwa semakin banyak mata kuliah yang diambil dan dikreditkan, kemungkinan besar nilai akhir mahasiswa juga lebih tinggi.
- Fitur Unemployment_rate berkorelasi negatif dengan GDP sebesar -0.34, yang sesuai secara ekonomi (semakin tinggi pengangguran, semakin rendah GDP).
- Age_at_enrollment memiliki korelasi sangat rendah dengan sebagian besar fitur akademik, menunjukkan bahwa usia saat masuk kuliah tidak terlalu memengaruhi performa akademik dalam data ini.

## Data Preparation / Preprocessing

Pada data preparation dilakukan beberapa tahapan berikut:
1. Feature Engineering:
Melakukan mapping pada kolom kategorikal untuk mengubah kode numerik menjadi label yang sesuai. Selain itu, juga dilakukan pembuatan fitur baru berupa rata-rata nilai dari dua semester. Juga dilakukan pembuatan fitur baru berupa approval rate dan credit rate. Binerisasi fitur Displaced, Educational_special_needs, Debtor, Tuition_fees_up_to_date, Scholarship_holder, dan International. Hasil transformasi ini juga disimpan ke dalam file .csv untuk keperluan analisis lanjutan seperti visualisasi atau dashboard.

2. Outlier Handling:
Menggunakan metode winsorizing untuk menangani outlier. Metode ini mempertahankan distribusi data tanpa menghapus nilai, dengan cara membatasi nilai ekstrem ke dalam batas tertentu.

3. Feature Selection:
  - Chi-Square Test digunakan untuk menilai pentingnya fitur kategorikal terhadap target variabel.
  - T-Test digunakan untuk mengevaluasi pengaruh fitur numerikal terhadap target.
  - ANOVA untuk memilih 15 fitur utama yang paling relevan dengan label target.

4. Train-Test Split:
Membagi data menjadi data latih dan data uji untuk proses modeling dan evaluasi.

5. Label Encoding Target:
Membuat label encoding untuk target variabel.

6. One-Hot Encoding:
Melakukan one-hot encoding pada fitur kategorikal.

7. Standardization:
Melakukan standardization pada fitur numerikal agar model dapat berfungsi optimal, terutama pada algoritma yang sensitif terhadap skala fitur.

8. SMOTE:
Oversampling untuk menangani imbalanced data.
"""

preparation_df = df.copy()

preparation_df.info()

# Feature engineering

# Mapping dictionary
marital_status_map = {
    1: "Single", 2: "Married", 3: "Widower", 4: "Divorced",
    5: "Facto union", 6: "Legally separated"
}

application_mode_map = {
    1: "1st phase - general contingent", 2: "Ordinance No. 612/93", 5: "1st phase - special (Azores)",
    7: "Other higher courses", 10: "Ordinance No. 854-B/99", 15: "International bachelor",
    16: "1st phase - special (Madeira)", 17: "2nd phase - general", 18: "3rd phase - general",
    26: "Ordinance 533-A/99 b2", 27: "Ordinance 533-A/99 b3", 39: "Over 23 years old",
    42: "Transfer", 43: "Change of course", 44: "Diploma holders",
    51: "Change institution/course", 53: "Short cycle diploma", 57: "Change inst/course (Intl)"
}

course_map = {
    33: "Biofuel Tech", 171: "Multimedia Design", 8014: "Social Service (Evening)",
    9003: "Agronomy", 9070: "Comm Design", 9085: "Vet Nursing", 9119: "Informatics Eng",
    9130: "Equinculture", 9147: "Management", 9238: "Social Service", 9254: "Tourism",
    9500: "Nursing", 9556: "Oral Hygiene", 9670: "Marketing", 9773: "Journalism",
    9853: "Basic Education", 9991: "Management (Evening)"
}

attendance_map = {1: "Daytime", 0: "Evening"}

prev_qualification_map = {
    1: "Secondary education", 2: "Bachelor", 3: "Degree", 4: "Master",
    5: "Doctorate", 6: "Ongoing Higher Ed", 9: "12th not completed", 10: "11th not completed",
    12: "Other 11th", 14: "10th", 15: "10th not completed", 19: "Basic Ed 3rd cycle",
    38: "Basic Ed 2nd cycle", 39: "Tech course", 40: "Higher Ed 1st cycle",
    42: "Prof Tech Course", 43: "Higher Ed Master"
}

nationality_map = {
    1: "Portuguese", 2: "German", 6: "Spanish", 11: "Italian", 13: "Dutch", 14: "English",
    17: "Lithuanian", 21: "Angolan", 22: "Cape Verdean", 24: "Guinean", 25: "Mozambican",
    26: "Santomean", 32: "Turkish", 41: "Brazilian", 62: "Romanian", 100: "Moldovan",
    101: "Mexican", 103: "Ukrainian", 105: "Russian", 108: "Cuban", 109: "Colombian"
}

mother_qualification_map = {
    1: "Sec Ed 12th", 2: "Bachelor", 3: "Degree", 4: "Master", 5: "Doctorate",
    6: "Ongoing HE", 9: "12th not completed", 10: "11th not completed", 11: "7th old",
    12: "Other 11th", 14: "10th", 18: "General commerce", 19: "Basic Ed 3rd cycle",
    22: "Technical-prof course", 26: "7th", 27: "2nd general HS", 29: "9th not completed",
    30: "8th", 34: "Unknown", 35: "Illiterate", 36: "Can read (no school)", 37: "Basic Ed 1st",
    38: "Basic Ed 2nd", 39: "Tech spec course", 40: "HE Degree 1st", 41: "Specialized HE",
    42: "Prof HE", 43: "HE Master", 44: "HE Doctorate", 44: "HE Doctorate"
}

father_qualification_map = {
    1: "Secondary Education - 12th Year of Schooling or Eq.", 2: "Higher Education - Bachelor's Degree",
    3: "Higher Education - Degree", 4: "Higher Education - Master's", 5: "Higher Education - Doctorate",
    6: "Frequency of Higher Education", 9: "12th Year of Schooling - Not Completed", 10: "11th Year of Schooling - Not Completed",
    11: "7th Year (Old)", 12: "Other - 11th Year of Schooling", 13: "2nd Year Complementary High School Course",
    14: "10th Year of Schooling", 18: "General Commerce Course", 19: "Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv.",
    20: "Complementary High School Course", 22: "Technical-professional Course", 25: "Complementary High School Course - Not Concluded",
    26: "7th Year of Schooling", 27: "2nd Cycle of the General High School Course", 29: "9th Year of Schooling - Not Completed",
    30: "8th Year of Schooling", 31: "General Course of Administration and Commerce", 33: "Supplementary Accounting and Administration",
    34: "Unknown", 35: "Can't Read or Write", 36: "Can Read Without 4th Year of Schooling", 37: "Basic Education 1st Cycle (4th/5th Year) or Equiv.",
    38: "Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv.", 39: "Technological Specialization Course", 40: "Higher Education - Degree (1st Cycle)",
    41: "Specialized Higher Studies Course", 42: "Professional Higher Technical Course", 43: "Higher Education - Master (2nd Cycle)",
    44: "Higher Education - Doctorate (3rd Cycle)"
}

mother_occupation_map = {
    0: "Student", 1: "Executive", 2: "Scientist", 3: "Technician", 4: "Admin staff",
    5: "Services/Security", 6: "Farmer/Fisher", 7: "Industry Worker", 8: "Machine Operator",
    9: "Unskilled", 10: "Military", 90: "Other", 99: "Blank", 122: "Health Prof",
    123: "Teacher", 125: "ICT Specialist", 131: "Tech - Sci/Eng", 132: "Tech - Health",
    134: "Tech - Legal/Social", 141: "Secretary/Clerk", 143: "Finance/Admin",
    144: "Other Admin", 151: "Service Worker", 152: "Seller", 153: "Care Worker",
    171: "Construction", 173: "Printing/Jeweler/Artisan", 175: "Food/Wood/Clothes",
    191: "Cleaner", 192: "Unskilled - Agriculture", 193: "Unskilled - Industry",
    194: "Meal Assistant"
}

father_occupation_map = {
    0: "Student", 1: "Legislative/Executive Power, Directors, Executive Managers", 2: "Specialists in Intellectual and Scientific Activities",
    3: "Intermediate Level Technicians and Professions", 4: "Administrative Staff", 5: "Personal Services, Security, Sellers",
    6: "Farmers and Skilled Agriculture/Fisheries Workers", 7: "Skilled Industry/Construction/Crafts Workers", 8: "Machine Operators and Assemblers",
    9: "Unskilled Workers", 10: "Armed Forces Professions", 90: "Other Situation", 99: "Blank", 101: "Armed Forces Officers", 102: "Armed Forces Sergeants",
    103: "Other Armed Forces Personnel", 112: "Admin/Commercial Services Directors", 114: "Hotel/Catering/Trade Services Directors",
    121: "Specialists - Physical Sciences, Engineering, etc.", 122: "Health Professionals", 123: "Teachers", 124: "Specialists - Finance, Admin, Public Relations",
    131: "Intermediate Science and Engineering Technicians", 132: "Intermediate Health Technicians", 134: "Intermediate Legal, Social, Cultural Technicians",
    135: "ICT Technicians", 141: "Office Workers, Secretaries, Data Operators", 143: "Operators - Financial, Registry, etc.",
    144: "Other Administrative Support Staff", 151: "Personal Service Workers", 152: "Sellers", 153: "Personal Care Workers",
    154: "Protection and Security Services", 161: "Market-oriented Skilled Farmers", 163: "Subsistence Farmers, Fishermen, Hunters",
    171: "Construction Workers (except Electricians)", 172: "Metalworking and Similar Workers", 174: "Electricity and Electronics Workers",
    175: "Food Processing, Woodworking, Clothing Craftsmen", 181: "Fixed Plant and Machine Operators", 182: "Assembly Workers",
    183: "Vehicle Drivers and Mobile Equipment Operators", 192: "Unskilled Agriculture, Fisheries, Forestry Workers",
    193: "Unskilled Industry, Construction, Transport Workers", 194: "Meal Preparation Assistants", 195: "Street Vendors and Service Providers"
}

# Biner sederhana
binary_map = {1: "Yes", 0: "No"}
gender_map = {1: "Male", 0: "Female"}

# Membuat fitur baru
preparation_df['avg_grade'] = (preparation_df['Curricular_units_1st_sem_grade'] + preparation_df['Curricular_units_2nd_sem_grade']) / 2
preparation_df['approval_rate_1st'] = preparation_df['Curricular_units_1st_sem_approved'] / (preparation_df['Curricular_units_1st_sem_enrolled'] + 1)
preparation_df['approval_rate_2nd'] = preparation_df['Curricular_units_2nd_sem_approved'] / (preparation_df['Curricular_units_2nd_sem_enrolled'] + 1)
preparation_df['credit_rate_1st'] = preparation_df['Curricular_units_1st_sem_credited'] / (preparation_df['Curricular_units_1st_sem_enrolled'] + 1)
preparation_df['credit_rate_2nd'] = preparation_df['Curricular_units_2nd_sem_credited'] / (preparation_df['Curricular_units_1st_sem_enrolled'] + 1)

# Menerapkan mapping
preparation_df["Marital_status"] = preparation_df["Marital_status"].map(marital_status_map)
preparation_df["Application_mode"] = preparation_df["Application_mode"].map(application_mode_map)
preparation_df["Course"] = preparation_df["Course"].map(course_map)
preparation_df["Daytime_evening_attendance"] = preparation_df["Daytime_evening_attendance"].map(attendance_map)
preparation_df["Previous_qualification"] = preparation_df["Previous_qualification"].map(prev_qualification_map)
preparation_df["Nacionality"] = preparation_df["Nacionality"].map(nationality_map)
preparation_df["Mothers_qualification"] = preparation_df["Mothers_qualification"].map(mother_qualification_map)
preparation_df["Fathers_qualification"] = preparation_df["Fathers_qualification"].map(father_qualification_map)
preparation_df["Mothers_occupation"] = preparation_df["Mothers_occupation"].map(mother_occupation_map)
preparation_df["Fathers_occupation"] = preparation_df["Fathers_occupation"].map(father_occupation_map)
preparation_df["Displaced"] = preparation_df["Displaced"].map(binary_map)
preparation_df["Educational_special_needs"] = preparation_df["Educational_special_needs"].map(binary_map)
preparation_df["Debtor"] = preparation_df["Debtor"].map(binary_map)
preparation_df["Tuition_fees_up_to_date"] = preparation_df["Tuition_fees_up_to_date"].map(binary_map)
preparation_df["Gender"] = preparation_df["Gender"].map(gender_map)
preparation_df["Scholarship_holder"] = preparation_df["Scholarship_holder"].map(binary_map)
preparation_df["International"] = preparation_df["International"].map(binary_map)

preparation_df.info()

# Menyimpan dataset ke file csv untuk keperluan dashboard analysis
preparation_df.to_csv('students_clean.csv', index=False)

# Cek jumlah outliers
numerical_update = preparation_df.select_dtypes(include=['int64', 'float64']).columns

Q1 = preparation_df[numerical_update].quantile(0.25)
Q3 = preparation_df[numerical_update].quantile(0.75)
IQR = Q3 - Q1

outlier_mask = (preparation_df[numerical_update] < (Q1 - 1.5 * IQR)) | (preparation_df[numerical_update] > (Q3 + 1.5 * IQR))

outliers_per_feature = outlier_mask.sum()

print("Jumlah outlier per fitur:")
print(outliers_per_feature.sort_values(ascending=False))

total_outliers = outlier_mask.sum().sum()
print(f"\nTotal jumlah outlier (sel): {total_outliers}")

# Menyalin dataframe dulu biar bisa dibandingkan
df_winsor = preparation_df.copy()

# Kolom yang ingin ditangani outliers-nya
cols_with_outliers = [
    'avg_grade',
    'Curricular_units_2nd_sem_grade',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_1st_sem_credited',
    'credit_rate_1st',
    'Application_order',
    'credit_rate_2nd',
    'Curricular_units_2nd_sem_credited',
    'Age_at_enrollment',
    'Curricular_units_1st_sem_enrolled',
    'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_1st_sem_without_evaluations',
    'Curricular_units_2nd_sem_without_evaluations',
    'Curricular_units_1st_sem_approved',
    'Previous_qualification_grade',
    'Curricular_units_1st_sem_evaluations',
    'Curricular_units_2nd_sem_evaluations',
    'Admission_grade',
    'Curricular_units_2nd_sem_approved'
]

# Winsorizing (5% bawah dan atas)
for col in cols_with_outliers:
    lower = df_winsor[col].quantile(0.01)
    upper = df_winsor[col].quantile(0.99)
    df_winsor[col] = df_winsor[col].clip(lower, upper)

# Mengatur ukuran figure (jumlah baris disesuaikan dengan jumlah kolom)
n_cols = 2
n_rows = (len(cols_with_outliers) + 1) // n_cols
plt.figure(figsize=(14, 5 * n_rows))

for i, col in enumerate(cols_with_outliers):
    # Sebelum Winsorizing
    plt.subplot(n_rows, n_cols * 2, i * 2 + 1)
    sns.boxplot(x=preparation_df[col], color='salmon')
    plt.title(f"Before Winsorizing - {col}")

    # Setelah Winsorizing
    plt.subplot(n_rows, n_cols * 2, i * 2 + 2)
    sns.boxplot(x=df_winsor[col], color='skyblue')
    plt.title(f"After Winsorizing - {col}")

plt.tight_layout()
plt.show()

df_winsor.info()

# Target
target = 'Status'

# Kolom kategorikal dan numerikal
categorical_cols = df_winsor.select_dtypes(include=['category']).columns.tolist()
numerical_cols = df_winsor.select_dtypes(include=['float64']).columns.tolist()

print("=== CHI-SQUARE TEST ===")
for col in categorical_cols:
    try:
        contingency_table = pd.crosstab(df_winsor[target], df_winsor[col])
        chi2, p, dof, expected = chi2_contingency(contingency_table)
        print(f"{col}: p-value = {p:.5f} {'< 0.05 ✅' if p < 0.05 else '>= 0.05 ❌'}")
    except Exception as e:
        print(f"{col}: Error - {e}")

print("\n=== T-TEST ===")
# Pastikan target hanya 2 kelas agar t-test valid
if df_winsor[target].nunique() == 2:
    classes = df_winsor[target].unique()
    for col in numerical_cols:
        try:
            group1 = df_winsor[df_winsor[target] == classes[0]][col]
            group2 = df_winsor[df_winsor[target] == classes[1]][col]
            t_stat, p = ttest_ind(group1, group2, equal_var=False, nan_policy='omit')
            print(f"{col}: p-value = {p:.5f} {'< 0.05 ✅' if p < 0.05 else '>= 0.05 ❌'}")
        except Exception as e:
            print(f"{col}: Error - {e}")
else:
    print("Target Status memiliki lebih dari 2 kelas. T-test hanya valid untuk 2 kelas.")

# Feature selection
X_cat = pd.get_dummies(df_winsor[categorical_cols], drop_first=True)
X_full = pd.concat([X_cat, df_winsor[numerical_cols]], axis=1)

y = df_winsor['Status']  # Target multiklas

selector = SelectKBest(score_func=f_classif, k=15)  # ANOVA F-test
X_new = selector.fit_transform(X_full, y)

selected_features = X_full.columns[selector.get_support()]
print("Top 15 features (categorical + numerical):\n", selected_features)

# Menyimpan fitur ke dalam dataframe baru
selected_features = [
    'Application_mode', 'Course','Debtor', 'Tuition_fees_up_to_date',
    'Mothers_qualification', 'Fathers_qualification',
    'Gender', 'Scholarship_holder',
    'Curricular_units_1st_sem_grade', 'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_2nd_sem_grade', 'avg_grade', 'approval_rate_1st',
       'approval_rate_2nd', 'Status'
    ]

df_selected = df_winsor[selected_features].copy()

df_selected.head()

# Split data
X = df_selected.drop('Status', axis=1)
y = df_selected['Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

X.info()

# Mengidentifikasi fitur kategorikal dan numerikal
categorical_features = [
    'Application_mode',
    'Course',
    'Debtor',
    'Tuition_fees_up_to_date',
    'Mothers_qualification',
    'Fathers_qualification',
    'Gender',
    'Scholarship_holder'
]

numerical_features = [
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_2nd_sem_grade',
    'avg_grade',
    'approval_rate_1st',
    'approval_rate_2nd'
]

# Label encoding target
le_target = LabelEncoder()
y_train_enc = le_target.fit_transform(y_train)
y_test_enc = le_target.transform(y_test)

# Preprocessing pipeline
preprocessor = ColumnTransformer([
    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),
    ('num', StandardScaler(), numerical_features)
])

# Transform data
X_train_proc = preprocessor.fit_transform(X_train)
X_test_proc = preprocessor.transform(X_test)

# Ubah ke array dense (dari sparse matrix)
X_train_proc = X_train_proc.toarray()
X_test_proc = X_test_proc.toarray()

# Konversi ke DataFrame untuk memastikan format yang benar
X_train_proc_df = pd.DataFrame(X_train_proc, columns=preprocessor.get_feature_names_out())

# SMOTE untuk menangani imbalanced data
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_proc_df, y_train_enc)

# Verifikasi dimensi data
print("Shape X_train_res:", X_train_res.shape)
print("Shape y_train_res:", y_train_res.shape)

"""## Modeling

Label target pada data ini adalah multiklas, sehingga perlu dilakukan pemodelan dengan beberapa model klasifikasi. Pada tahap ini dilakukan 2 hal berikut:

- Model Tuning dengan GridSearchCV untuk XGBoost
- Ensemble Model dengan XGBoost, Random Forest, dan Logistic Regression
- Training semua model
"""

# Model Tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5, 6],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
    'min_child_weight': [1, 3, 5]
}

xgb_model = xgb.XGBClassifier(eval_metric='mlogloss', random_state=42)
grid_search = GridSearchCV(
    xgb_model,
    param_grid,
    cv=3,
    scoring='f1_macro',
    n_jobs=-1
)

grid_search.fit(X_train_res, y_train_res)

print("Best XGBoost params:", grid_search.best_params_)
print("Best XGBoost CV F1 macro:", grid_search.best_score_)

# Ensemble Model
best_xgb = grid_search.best_estimator_
rf_model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)
lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')

# Model dictionary
models = {
    'XGBoost': best_xgb,
    'Random Forest': rf_model,
    'Logistic Regression': lr_model
}

# Training semua model dengan hasil SMOTE
trained_models = {}
for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train_res, y_train_res)
    trained_models[name] = model

"""## Evaluation

Karena model yang digunakan adalah klasifikasi, maka evaluasi model yang digunakan adalah accuracy, precision, recall, dan f1-score. Selain itu, juga dilakukan visualisasi confusion matrix dan feature importance.

Selanjutnya model terbaik beserta komponen preprocessing disimpan untuk keperluan deployment.
"""

# Evaluasi model
for name, model in trained_models.items():
    y_pred = model.predict(X_test_proc)

    print(f"\n{name} Performance:")
    print(f"Accuracy: {accuracy_score(y_test_enc, y_pred):.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test_enc, y_pred, target_names=le_target.classes_))

    # Confusion Matrix
    cm = confusion_matrix(y_test_enc, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=le_target.classes_,
                yticklabels=le_target.classes_)
    plt.title(f'Confusion Matrix - {name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

"""Berdasarkan hasil tersebut, model terbaik yaitu XGBoost. Model XGBoost dipilih sebagai model terbaik karena memberikan performa paling seimbang di antara ketiga model yang diuji. Meskipun seluruh model memiliki akurasi yang serupa (sekitar 73%), XGBoost unggul dalam menghasilkan nilai f1-score yang stabil di ketiga kelas (Dropout, Enrolled, Graduate), tanpa terlalu condong ke satu kelas tertentu. Hal ini menunjukkan bahwa XGBoost mampu menangani variasi data dengan baik dan memberikan prediksi yang lebih konsisten, menjadikannya pilihan yang paling andal dalam konteks klasifikasi status mahasiswa."""

# Feature Importance untuk Logistic Regression, Random Forest, dan XGBoost
for name, model in trained_models.items():
    if name == 'Logistic Regression':
        coefs = model.coef_[0]  # multi-class: shape = (n_classes, n_features)
        feature_importance = pd.Series(np.abs(coefs), index=preprocessor.get_feature_names_out())
        plt.figure(figsize=(10, 6))
        feature_importance.sort_values(ascending=False).head(10).plot(kind='bar')
        plt.title('Top 10 Coefficients - Logistic Regression')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()
    if name in ['Random Forest', 'XGBoost']:
        if name == 'Random Forest':
            importances = model.feature_importances_
        else:
            importances = model.feature_importances_

        feature_importance = pd.Series(importances, index=preprocessor.get_feature_names_out())
        plt.figure(figsize=(10, 6))
        feature_importance.sort_values(ascending=False).head(10).plot(kind='bar')
        plt.title(f'Top 10 Feature Importance - {name}')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

# Membuat direktori model jika belum ada
model_dir = 'model'
os.makedirs(model_dir, exist_ok=True)

# Menyimpan komponen preprocessing
preprocessing_components = {
    'preprocessor': preprocessor,
    'label_encoder': le_target,
    'categorical_features': categorical_features,
    'numerical_features': numerical_features
}

# Menyimpan komponen preprocessing dan model
joblib.dump(preprocessing_components, os.path.join(model_dir, 'preprocessing_components.joblib'))
joblib.dump(grid_search.best_estimator_, os.path.join(model_dir, 'best_model.joblib'))

print("Model dan komponen preprocessing berhasil disimpan")